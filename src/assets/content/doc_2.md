# 2. Quality Assurance Activities Overview

This guide is designed to enhance the integration of Design Quality Assurance (DQA) into the Agile project lifecycle. By following the activities outlined below and promoting effective collaboration, our aim is to deliver high-quality design outcomes that meet client expectations and reduce the risk of errors. This guide provides clarity, responsibilities, and methods for measuring success.

---

## Team Roles for Successful DQA wip

Designers have a crucial role in ensuring the product’s visual quality matches the design, similar to how a QA Developer manages QA approval. To ensure successful DQA integration, effective collaboration among Designers, Developers, and Product Managers is vital. Here’s how each role contributes:

|**Role**|**Responsibilities**|
|---|---|
|**Designers**|- **Align and Advocate:** Actively guide the team to align on design implementation, fostering clear communication.<br>    <br>- **Collaborate for Balance:** Work with Product Management to balance stakeholder, business, and user goals, documenting Acceptance Criteria.<br>    <br>- **Streamline Development:** Provide clear communication through annotations and Figma onboarding to enhance design-development efficiency.<br>    <br>- **Ensure QA:** Conduct thorough Design QA to meet standards and user expectations and verify adherence to acceptance criteria.|
|**Developers**|- **Communicate challenges and complexities** that may lead to deviations from the original design. Early communication ensures that the design can be adjusted as needed without compromising user experience.|
|**Product & Delivery Managers**|- **Design Insights:** Collaborate with Designers to understand design constraints and possibilities, enabling informed decisions balancing business goals and user experience.<br>    <br><br>- **Timeline Management:** Set project timelines for thorough DQA without compromising quality, considering iterative design improvement.|
|**All Team**|- **Timely Feedback:** Team members provide timely feedback, contributing to design improvement and project alignment.<br>    <br>- **Adaptability Culture:** Foster adaptability and continuous enhancement, embracing adjustments based on design feedback to keep the process dynamic and responsive.|

By fostering a collaborative environment and understanding each other’s roles and expectations, we can optimize the Design QA process and collectively contribute to the successful delivery of high-quality design outcomes.

---

## Design QA Touchpoints and Activities wip

Here’s a concise summary of the Design QA touchpoints and activities for each Agile phase:

|**Phase**|**Design QA Activities**|
|---|---|
|**Define**<br><br>Refines project requirements and formulates design concepts.|- Introduce Design QA concepts and processes and communicate the importance of Design QA within the project.<br>    <br>- Align the team on Design QA objectives.<br>    <br>- Evaluate visual design for accessibility compliance.|
|**Deploy**<br><br>Development and design activities come together.|- Test the UI for functionality, usability, accessibility and visual consistency.<br>    <br>- Verify design compatibility across browsers and devices.<br>    <br>- Document and monitor design bugs in development|
|**UAT & Launch**<br><br>Ensures final design outputs align with project objectives and requirements.|- Create reports, document issues, and track quality assurance process.|

---

## Common Pitfalls in Design QA

In our quest for impeccable design quality, it’s essential to be aware of and steer clear of these common pitfalls that can hamper our efforts and project success.

1. **Lack of Stakeholder Alignment:** Ensure everyone understands the importance of design QA.
2. **Inadequate Documentation:** Keep clear records of processes and findings.
3. **Scope Creep:** Define and stick to the scope of design QA.
4. **Expecting Perfection:** Don’t assume designs will be flawless.
5. **Isolation:** Collaborate with the entire team, including developers and product managers.
6. **Neglecting Usability:** Consider user perspectives and usability.
7. **Ignoring Feedback:** Take design issues seriously.
8. **Inconsistent Standards:** Maintain design consistency.
9. **Rigid Processes:** Be flexible to adapt to project needs.
10. **Underestimating Resources:** Allocate sufficient time and resources.
11. **Issue Prioritization:** Prioritize critical issues.
12. **Losing Focus:** Keep sight of project goals.

---

## Measuring Improvement

As part of our ongoing efforts to enhance workflow effectiveness, we are dedicated to elevating the quality of design deliverables and reducing visual discrepancies. To validate these changes, we should employ the following methods to track progress:

- **Defect Density:** We gauge the number of design-related defects per completed unit of work, aiming to see a consistent decrease over time. This metric provides insights into our ability to consistently adhere to design specifications.
- **Percentage of Reopened Tickets:** Our focus is on monitoring the percentage of reopened tickets attributed to design-related issues, striving for a continuous downward trend. A decrease indicates improved accuracy and alignment with the original design intent.
- **User Satisfaction:** Gathering feedback from both users and stakeholders regarding design quality is essential. This feedback loop helps us iteratively enhance our processes and adapt to evolving user needs.
- **Design Dev Alignment Index:** Introducing a metric that quantifies the alignment between the developed product and the original design. This index reflects our success in translating design concepts into functional products accurately.
- **Visual Delta Report:** Regularly reviewing and disseminating a comprehensive report that highlights discrepancies and improvements observed between design and development phases. This report reinforces transparency and ensures that all stakeholders are aware of the evolution of the design throughout the project lifecycle.

By employing these measurement methods, we continuously validate the effectiveness of our improvements, reinforcing our commitment to delivering high-quality design outcomes and seamless user experiences.

---

## Team Maturity

Design QA needs are determined by the team’s maturity and how closely they adhere to design specifications. Here’s a breakdown based on team maturity levels:

**Level 1 (Highly Mature):**

- Deviations are rare due to a strong track record of successful projects.
- Less Design QA is required, as the team accurately follows guidelines.

**Level 2 (Moderately Mature):**

- Some deviations occur, often due to unforeseen challenges or complexity.
- Moderate Design QA is needed to manage deviations based on project complexity.

**Level 3 (Less Mature):**

- More deviations occur, possibly due to inexperience or skill gaps.
- Substantial Design QA is essential for oversight and early deviation detection.

In summary, team maturity inversely affects the need for Design QA. More mature teams require less, while less mature teams need more to manage deviations.

---

## Design Support Scenarios

Different levels of design support align with project requirements:

|**Level of Design Support**|**Description**|
|---|---|
|No Design Support|The project does not involve any design work, and design decisions are not a consideration.|
|Limited Design Support|The project includes some design work, but it is limited in scope or importance. Design decisions may be made by non-designers, or the project may not have a dedicated designer.|
|Moderate Design Support|The project includes a significant amount of design work, and design decisions are an important consideration. The project may have a dedicated designer or design team, and design decisions are made collaboratively with other stakeholders.|
|High Design Support|The project is heavily focused on design, and design decisions have a significant impact on the project’s success. The project has a dedicated design team, and design decisions are made collaboratively with other stakeholders. Design is seen as a key differentiator for the project.|

It’s important to note that the level of design support needed for a project will depend on various factors such as the complexity of the project, budget, timeline, and the overall importance of design in achieving project goals.

---

## Conclusion and Key Takeaways

This guide aims to provide clarity and guidance for integrating Design QA into the Agile project lifecycle. By following these activities and collaborating effectively, we aim to deliver high-quality design outputs that meet client expectations and reduce the risk of errors.

- Designers play a crucial role in shaping product visuals and user experiences.
- Design Quality Assurance (DQA) ensures design meets standards and user expectations.
- Collaboration among Designers, Developers, and Product Managers is vital.
- DQA activities like design audits contribute to high-quality design.
- Methods like Defect Density track design quality improvements.

Remember, fostering a culture of collaboration, adaptability, and continuous enhancement is key to achieving high-quality design deliverables and meeting project goals.

For any questions or clarifications, please reach out to the Design QA team.

**Disclaimer:** This guide is for informational purposes only and is subject to change based on evolving project needs and best practices.

---

Next Section:

[https://myplanet.jira.com/wiki/spaces/DQA/pages/407175175](https://myplanet.jira.com/wiki/spaces/DQA/pages/407175175)

**Team Size and Project Impact:**

- Larger teams can efficiently handle Discovery/Research and may complete it more quickly, leading to a reduced time percentage.
    
- Smaller teams may require more time for Component Estimation in the Design/Planning phase due to limited resources
    
- Larger teams can allocate dedicated designers, allowing for more comprehensive design reviews in the Design/Planning phase
    
- Larger teams may have the capacity for parallel UI testing and simultaneous Cross-Browser/Device Testing in the Development/Deployment phase
    
- Larger teams with dedicated accessibility experts can efficiently conduct Accessibility Testing and address any issues promptly during the Testing/Quality Assurance phase
    
- Larger teams can dedicate resources to streamline documentation and reporting in the Review/Retrospective phase, reducing the time required
    

*Note: The time percentages represent the estimated allocation of time for each phase. The total percentage

**2.2 Overview of Quality Assurance Activities**

Here’s a summary of the activities, their time requirements as a percentage, and how they may change based on team size and project type:

|**Phase: Discovery/Research**|**Time: 10-15%**|**Team Size/Project Impact**|**Level of Design Support**|**Description**|**Team Member**|
|---|---|---|---|---|---|
|User Research and Requirements Gathering|10%|Larger teams: Efficient data collection and defining project scope|Limited Design Support|Conduct user research, gather requirements, and define the project scope and objectives.|Designer, User Researcher|

|**Phase: Design/Planning**|**Time: 15-20%**|**Team Size/Project Impact**|**Level of Design Support**|**Description**|**Team Member**|
|---|---|---|---|---|---|
|Current Asset Design Audit|15%|Larger teams: More efficient audit of existing design assets|Moderate Design Support|Conduct an audit of existing design assets to assess their relevance, quality, and usability for the project.|Designer|
|Initial Sales SOW Component Estimation|15%|Smaller teams: More time for estimation|Moderate Design Support|Analyze the Sales Statement of Work (SOW) to estimate the number of design components needed.|Designer|
|Design Review and Feedback|20%|Allocation of designer is critical for thorough design reviews|High Design Support|Review design elements, gather feedback, and iterate on concepts before development begins.|Designer|

|**Phase: Development/Deployment**|**Time: 25-40%**|**Team Size/Project Impact**|**Level of Design Support**|**Description**|**Team Member**|
|---|---|---|---|---|---|
|User Interface (UI) Testing|25%|Larger teams: Parallel UI testing for reduced time|High Design Support|Test UI functionality, usability, and visual consistency during development.|Design and QA Analyst|
|Documentation and Reporting|5%|Larger teams: Dedicated resources streamline documentation|Limited Design Support|Create reports, document issues, and track overall quality assurance process at the end of each sprint.|Designer|
|Cross-Browser/Device Testing|30%|Larger teams: Simultaneous testing for cross-platform consistency|High Design Support|Test visual elements and design compatibility across browsers and devices.|QA Analyst|

|**Phase: Testing/Quality Assurance**|**Time: 20-25%**|**Team Size/Project Impact**|**Level of Design Support**|**Description**|**Team Member**|
|---|---|---|---|---|---|
|Accessibility Testing|20%|Larger teams: Efficient testing and issue resolution|Moderate Design Support|Evaluate design for accessibility compliance and ensure usability by individuals with disabilities.|Designer, Accessibility Specialist|
|Visual Regression Testing|25%|Larger teams: Automated testing for efficient results|Moderate Design Support|Compare visual output of current version with previous ones to identify unintended changes during testing.|QA Analyst and Designer|